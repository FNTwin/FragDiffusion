{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found rdkit, all good\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import dgd\n",
    "import datamol as dm\n",
    "from dgd.analysis.rdkit_functions import *\n",
    "from dgd.diffusion_model_discrete import DiscreteDenoisingDiffusion\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'general': {'name': 'run_1000dsteps_128batch', 'wandb': 'offline', 'gpus': 1, 'entity': 'fntwin', 'project': 'SAFE_SPACE', 'resume': None, 'test_only': None, 'check_val_every_n_epochs': 5, 'sample_every_val': 4, 'val_check_interval': None, 'samples_to_generate': 512, 'samples_to_save': 20, 'chains_to_save': 1, 'log_every_steps': 50, 'number_chain_steps': 50, 'overfit': 0, 'progress_bar': True, 'final_model_samples_to_generate': 10000, 'final_model_samples_to_save': 30, 'final_model_chains_to_save': 20, 'evaluate_all_checkpoints': False}, 'model': {'type': 'discrete', 'transition': 'marginal', 'model': 'graph_tf', 'diffusion_steps': 1000, 'diffusion_noise_schedule': 'cosine', 'n_layers': 5, 'extra_features': 'cycles', 'hidden_mlp_dims': {'X': 256, 'E': 128, 'y': 128}, 'hidden_dims': {'dx': 256, 'de': 64, 'dy': 64, 'n_head': 8, 'dim_ffX': 256, 'dim_ffE': 128, 'dim_ffy': 128}, 'lambda_train': [5, 0]}, 'train': {'n_epochs': 3000, 'batch_size': 256, 'lr': 0.0002, 'clip_grad': None, 'save_model': True, 'num_workers': 0, 'ema_decay': 0, 'weight_decay': 1e-12, 'optimizer': 'adamw', 'amsgrad': True, 'seed': 0}, 'dataset': {'name': 'frag', 'remove_h': None}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = \"/home/cristian_valencediscovery_com/dev/FragDiffusion/dgd/expts/outputs/2023-09-05/14-41-22/.hydra/config.yaml\"\n",
    "config = OmegaConf.load(config)\n",
    "config[\"general\"][\"wandb\"] = \"disabled\"\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset /home/cristian_valencediscovery_com/dev/FragDiffusion/dgd/datasets/../../data/frag/mol_frag_graphs_100000.pt.gz loaded from file\n",
      "Dataset sizes: train 64000, val 16000, test 20000\n",
      "Saving split indices to /home/cristian_valencediscovery_com/dev/FragDiffusion/notebooks\n",
      "[Noise schedule: cosine] alpha_bar: tensor([9.9996e-01, 9.9991e-01, 9.9986e-01,  ..., 9.6956e-06, 2.4239e-06,\n",
      "        2.4243e-10])\n",
      "Marginal distribution of the classes: tensor([0.2283, 0.0823, 0.0596, 0.0391, 0.0321, 0.0351, 0.0261, 0.0286, 0.0280,\n",
      "        0.0195, 0.0157, 0.0166, 0.0199, 0.0132, 0.0130, 0.0145, 0.0149, 0.0116,\n",
      "        0.0141, 0.0127, 0.0095, 0.0092, 0.0110, 0.0073, 0.0066, 0.0066, 0.0068,\n",
      "        0.0068, 0.0054, 0.0063, 0.0060, 0.0081, 0.0047, 0.0070, 0.0053, 0.0062,\n",
      "        0.0056, 0.0057, 0.0047, 0.0045, 0.0054, 0.0063, 0.0049, 0.0032, 0.0052,\n",
      "        0.0050, 0.0044, 0.0042, 0.0033, 0.0037, 0.0037, 0.0032, 0.0024, 0.0029,\n",
      "        0.0030, 0.0030, 0.0029, 0.0033, 0.0034, 0.0018, 0.0019, 0.0023, 0.0025,\n",
      "        0.0023, 0.0028, 0.0023, 0.0019, 0.0016, 0.0023, 0.0022, 0.0019, 0.0022,\n",
      "        0.0022, 0.0015, 0.0016, 0.0013, 0.0020, 0.0012, 0.0017, 0.0014, 0.0017,\n",
      "        0.0010, 0.0016, 0.0017, 0.0016, 0.0016, 0.0015, 0.0013, 0.0014, 0.0016,\n",
      "        0.0014, 0.0011, 0.0014, 0.0015, 0.0014, 0.0013, 0.0011, 0.0010, 0.0013,\n",
      "        0.0010]) for nodes, tensor([0.7337, 0.1000, 0.0821, 0.0843]) for edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristian_valencediscovery_com/mambaforge/envs/fragdiff/lib/python3.11/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "/home/cristian_valencediscovery_com/mambaforge/envs/fragdiff/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'train_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['train_metrics'])`.\n",
      "  rank_zero_warn(\n",
      "/home/cristian_valencediscovery_com/mambaforge/envs/fragdiff/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'sampling_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['sampling_metrics'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"/home/cristian_valencediscovery_com/dev/FragDiffusion/dgd/expts/outputs/2023-09-05/14-41-22/checkpoints/run_1000dsteps_128batch/epoch=759.ckpt\"\n",
    "model=DiscreteDenoisingDiffusion.from_config(config, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of generated X:  tensor([12,  0,  9,  1, 47,  4, 14])\n",
      "Example of generated E:  tensor([[0, 1, 0, 0, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 2, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 3, 0, 2],\n",
      "        [1, 0, 0, 3, 0, 0, 0],\n",
      "        [0, 2, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 2, 0, 0, 0]])\n",
      "Example of generated X:  tensor([64, 51, 48, 17,  3,  2,  0])\n",
      "Example of generated E:  tensor([[0, 0, 2, 0, 2, 3, 2],\n",
      "        [0, 0, 0, 0, 0, 0, 3],\n",
      "        [2, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0],\n",
      "        [2, 0, 0, 0, 0, 0, 0],\n",
      "        [3, 0, 0, 1, 0, 0, 0],\n",
      "        [2, 3, 0, 0, 0, 0, 0]])\n",
      "Example of generated X:  tensor([40,  2,  4,  1,  9, 76,  4])\n",
      "Example of generated E:  tensor([[0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 3, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 3, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 3, 0, 3, 0, 0, 3],\n",
      "        [0, 0, 0, 0, 0, 3, 0]])\n"
     ]
    }
   ],
   "source": [
    "mols=model.random_sample(batch_id = 1, batch_size=5, sanitize=True, num_nodes=7, return_samples=True)\n",
    "#dm.viz.to_image(mols, use_svg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([12,  0,  9,  1, 47,  4, 14]),\n",
       "  tensor([[0, 1, 0, 0, 1, 0, 0],\n",
       "          [1, 0, 0, 0, 0, 2, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 3, 0, 2],\n",
       "          [1, 0, 0, 3, 0, 0, 0],\n",
       "          [0, 2, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 2, 0, 0, 0]])],\n",
       " [tensor([64, 51, 48, 17,  3,  2,  0]),\n",
       "  tensor([[0, 0, 2, 0, 2, 3, 2],\n",
       "          [0, 0, 0, 0, 0, 0, 3],\n",
       "          [2, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 1, 0],\n",
       "          [2, 0, 0, 0, 0, 0, 0],\n",
       "          [3, 0, 0, 1, 0, 0, 0],\n",
       "          [2, 3, 0, 0, 0, 0, 0]])],\n",
       " [tensor([40,  2,  4,  1,  9, 76,  4]),\n",
       "  tensor([[0, 0, 0, 0, 0, 1, 0],\n",
       "          [0, 0, 0, 0, 0, 3, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 1, 3, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0],\n",
       "          [1, 3, 0, 3, 0, 0, 3],\n",
       "          [0, 0, 0, 0, 0, 3, 0]])],\n",
       " [tensor([ 0, 22,  9,  0,  9,  6,  1]),\n",
       "  tensor([[0, 2, 0, 0, 0, 0, 0],\n",
       "          [2, 0, 0, 3, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 1],\n",
       "          [0, 3, 0, 0, 0, 1, 3],\n",
       "          [0, 0, 0, 0, 0, 0, 3],\n",
       "          [0, 0, 0, 1, 0, 0, 0],\n",
       "          [0, 0, 1, 3, 3, 0, 0]])],\n",
       " [tensor([56, 31,  7,  0,  1, 55,  6]),\n",
       "  tensor([[0, 2, 3, 1, 0, 0, 0],\n",
       "          [2, 0, 0, 0, 3, 0, 1],\n",
       "          [3, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 3, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 3],\n",
       "          [0, 1, 0, 0, 0, 3, 0]])]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found rdkit, all good\n",
      "Restored variables from /home/cristian_valencediscovery_com/dev/FragDiffusion/dgd/analysis/scscore/model.ckpt-10654.as_numpy.pickle\n",
      "Validity over 5 molecules: 40.00%\n",
      "Number of connected components of 5 molecules: min:1.00 mean:1.00 max:1.00\n",
      "Relaxed validity over 5 molecules: 40.00%\n",
      "Uniqueness over 2 valid molecules: 100.00%\n",
      "Novelty over 2 unique valid molecules: 100.00%\n",
      "{'samples/Validity': 0.4, 'samples/Relaxed Validity': 0.4, 'samples/Uniqueness': 1.0, 'samples/Novelty': 1.0, 'samples/LogP': 0.8018399999999998, 'samples/QED': 0.3521465389686161, 'samples/SA_Score': 1.2525998577872255, 'samples/SCScore': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:23:58] Explicit valence for atom # 15 C, 5, is greater than permitted\n",
      "[09:23:58] Explicit valence for atom # 9 C, 5, is greater than permitted\n",
      "[09:23:58] Explicit valence for atom # 5 N, 6, is greater than permitted\n",
      "[09:23:58] Explicit valence for atom # 15 C, 5, is greater than permitted\n",
      "[09:23:58] Explicit valence for atom # 9 C, 5, is greater than permitted\n",
      "[09:23:58] Explicit valence for atom # 5 N, 6, is greater than permitted\n",
      "/home/cristian_valencediscovery_com/dev/FragDiffusion/dgd/analysis/scscore/scscore.py:80: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  dtype=np.bool,\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'graphs/run_1000dsteps_128batch/valid_unique_molecules_e0_b-1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49msampling_metrics(mols, model\u001b[39m.\u001b[39;49mname, model\u001b[39m.\u001b[39;49mcurrent_epoch, val_counter\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, test\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/fragdiff/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dev/FragDiffusion/dgd/metrics/molecular_metrics.py:88\u001b[0m, in \u001b[0;36mSamplingMolecularRDKitMetrics.forward\u001b[0;34m(self, molecules, name, current_epoch, val_counter, test)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAll smiles saved\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m valid_unique_molecules \u001b[39m=\u001b[39m rdkit_metrics[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 88\u001b[0m textfile \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m     89\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgraphs/\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m/valid_unique_molecules_e\u001b[39m\u001b[39m{\u001b[39;00mcurrent_epoch\u001b[39m}\u001b[39;00m\u001b[39m_b\u001b[39m\u001b[39m{\u001b[39;00mval_counter\u001b[39m}\u001b[39;00m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     91\u001b[0m )\n\u001b[1;32m     92\u001b[0m textfile\u001b[39m.\u001b[39mwritelines(valid_unique_molecules)\n\u001b[1;32m     93\u001b[0m textfile\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'graphs/run_1000dsteps_128batch/valid_unique_molecules_e0_b-1.txt'"
     ]
    }
   ],
   "source": [
    "model.sampling_metrics(mols, model.name, model.current_epoch, val_counter=-1, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<rdkit.Chem.rdchem.Mol at 0x7ff8a3b83d10>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a3b82b20>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a3b83df0>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a3b83f40>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a3b83760>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a3b83ca0>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a3b83d80>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a3b83300>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a3b83a70>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a3b81d20>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a3b82490>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a3550350>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a35506d0>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7ff8a3550200>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pathlib\n",
    "import hydra\n",
    "import os, sys\n",
    "import torch\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "import hydra\n",
    "import omegaconf\n",
    "from omegaconf import DictConfig\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.utilities.warnings import PossibleUserWarning\n",
    "\n",
    "from dgd import utils\n",
    "from dgd.datasets.frag_dataset import FragDataset, FragDataModule, FragDatasetInfos\n",
    "from dgd.analysis.frag_utils import PyGGraphToMolConverter, FragSamplingMetrics\n",
    "from dgd.datasets.frag_dataset import FRAG_GRAPH_FILE, FRAG_INDEX_FILE, FRAG_EDGE_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 100\n",
      "4 4\n",
      "6 0\n"
     ]
    }
   ],
   "source": [
    "print(model.Xdim, model.Xdim_output)\n",
    "print(model.Edim, model.Edim_output)\n",
    "print(model.ydim, model.ydim_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DiscreteDenoisingDiffusion is not attached to a `Trainer`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mon_fit_start()\n",
      "File \u001b[0;32m~/dev/FragDiffusion/dgd/diffusion_model_discrete.py:198\u001b[0m, in \u001b[0;36mDiscreteDenoisingDiffusion.on_fit_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_fit_start\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_iterations \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39mdatamodule\u001b[39m.\u001b[39mtrain_dataloader())\n\u001b[1;32m    199\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSize of the input features\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mXdim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mEdim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mydim)\n",
      "File \u001b[0;32m~/mambaforge/envs/fragdiff/lib/python3.11/site-packages/pytorch_lightning/core/module.py:203\u001b[0m, in \u001b[0;36mLightningModule.trainer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m _TrainerFabricShim(fabric\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fabric)  \u001b[39m# type: ignore[return-value]\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_is_scripting \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is not attached to a `Trainer`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DiscreteDenoisingDiffusion is not attached to a `Trainer`."
     ]
    }
   ],
   "source": [
    "model.on_fit_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset /home/cristian_valencediscovery_com/dev/FragDiffusion/dgd/datasets/../../data/frag/mol_frag_graphs_100000.pt.gz loaded from file\n",
      "Dataset sizes: train 64000, val 16000, test 20000\n",
      "Saving split indices to /home/cristian_valencediscovery_com/dev/FragDiffusion/notebooks\n"
     ]
    }
   ],
   "source": [
    "def get_dataloader(config):\n",
    "    from dgd.diffusion.extra_features import DummyExtraFeatures, ExtraFeatures\n",
    "    datamodule = FragDataModule(config)\n",
    "    dataset_infos=config[\"dataset\"]\n",
    "    dataset_infos = FragDatasetInfos(datamodule,dataset_infos)\n",
    "    if config.model.type == 'discrete' and config.model.extra_features is not None:\n",
    "        extra_features = ExtraFeatures(config.model.extra_features, dataset_info=dataset_infos)\n",
    "    else:\n",
    "        extra_features = DummyExtraFeatures()\n",
    "    domain_features = DummyExtraFeatures()\n",
    "\n",
    "    dataset_infos.compute_input_output_dims(datamodule=datamodule, extra_features=extra_features,\n",
    "                                            domain_features=domain_features)\n",
    "    return datamodule, dataset_infos\n",
    "\n",
    "datamod, infos=get_dataloader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(iter(datamod.train_dataloader()))\n",
    "ex_dense, node_mask = utils.to_dense(\n",
    "            example_batch.x,\n",
    "            example_batch.edge_index,\n",
    "            example_batch.edge_attr,\n",
    "            example_batch.batch,\n",
    "        )\n",
    "example_data = {\n",
    "            \"X_t\": ex_dense.X,\n",
    "            \"E_t\": ex_dense.E,\n",
    "            \"y_t\": example_batch[\"y\"],\n",
    "            \"node_mask\": node_mask,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7,  8,  7,  8,  6,  9,  7,  8, 10,  6])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos.nodes_dist.sample_n(10, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset /home/cristian_valencediscovery_com/dev/FragDiffusion/dgd/datasets/../../data/../data/frag/mol_frag_graphs_100000.pt.gz loaded from file\n"
     ]
    }
   ],
   "source": [
    "from dgd import utils\n",
    "frags=FragDataset(\"../data/frag/mol_frag_graphs_100000.pt.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frags[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset /home/cristian_valencediscovery_com/dev/FragDiffusion/dgd/datasets/../../data/frag/mol_frag_graphs_100000.pt.gz loaded from file\n",
      "Data(x=[11, 100], edge_index=[2, 20], edge_attr=[20, 4], y=[1, 0], idx=0, n_nodes=[1])\n",
      "Dataset sizes: train 64000, val 16000, test 20000\n",
      "Saving split indices to /home/cristian_valencediscovery_com/dev/FragDiffusion/notebooks\n"
     ]
    }
   ],
   "source": [
    "from dgd.datasets.abstract_dataset import AbstractDataModule\n",
    "datamod.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t\u001b[39m.\u001b[39;49mtrain_dataloader()\n",
      "File \u001b[0;32m~/dev/FragDiffusion/dgd/datasets/abstract_dataset.py:30\u001b[0m, in \u001b[0;36mAbstractDataModule.train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_dataloader\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloaders[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "t.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "for data in datamod.dataloaders[\"train\"]:\n",
    "    num_classes = data.x.shape[1]\n",
    "\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[1783, 100], edge_index=[2, 3054], edge_attr=[3054, 4], y=[256, 0], idx=[256], n_nodes=[256], batch=[1783], ptr=[257])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(iter(datamod.train_dataloader())))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_data, node_mask = utils.to_dense(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "dense_data = dense_data.mask(node_mask)\n",
    "X, E = dense_data.X, dense_data.E\n",
    "noisy_data = model.apply_noise(X, E, data.y, node_mask)\n",
    "extra_data = model.compute_extra_data(noisy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (15) must match the size of tensor b (12) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mforward(noisy_data, extra_data, node_mask)\u001b[39m.\u001b[39mX\u001b[39m.\u001b[39msize()\n",
      "File \u001b[0;32m~/dev/FragDiffusion/dgd/diffusion_model_discrete.py:550\u001b[0m, in \u001b[0;36mDiscreteDenoisingDiffusion.forward\u001b[0;34m(self, noisy_data, extra_data, node_mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m E \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((noisy_data[\u001b[39m'\u001b[39m\u001b[39mE_t\u001b[39m\u001b[39m'\u001b[39m], extra_data\u001b[39m.\u001b[39mE), dim\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m    549\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhstack((noisy_data[\u001b[39m'\u001b[39m\u001b[39my_t\u001b[39m\u001b[39m'\u001b[39m], extra_data\u001b[39m.\u001b[39my))\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m--> 550\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(X, E, y, node_mask)\n",
      "File \u001b[0;32m~/mambaforge/envs/fragdiff/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dev/FragDiffusion/dgd/models/transformer_model.py:317\u001b[0m, in \u001b[0;36mGraphTransformer.forward\u001b[0;34m(self, X, E, y, node_mask)\u001b[0m\n\u001b[1;32m    313\u001b[0m new_E \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_in_E(E)\n\u001b[1;32m    314\u001b[0m new_E \u001b[39m=\u001b[39m (new_E \u001b[39m+\u001b[39m new_E\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    315\u001b[0m after_in \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mPlaceHolder(\n\u001b[1;32m    316\u001b[0m     X\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp_in_X(X), E\u001b[39m=\u001b[39;49mnew_E, y\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp_in_y(y)\n\u001b[0;32m--> 317\u001b[0m )\u001b[39m.\u001b[39;49mmask(node_mask)\n\u001b[1;32m    318\u001b[0m X, E, y \u001b[39m=\u001b[39m after_in\u001b[39m.\u001b[39mX, after_in\u001b[39m.\u001b[39mE, after_in\u001b[39m.\u001b[39my\n\u001b[1;32m    320\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_layers:\n",
      "File \u001b[0;32m~/dev/FragDiffusion/dgd/utils.py:294\u001b[0m, in \u001b[0;36mPlaceHolder.mask\u001b[0;34m(self, node_mask, collapse)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mE[(e_mask1 \u001b[39m*\u001b[39m e_mask2)\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX \u001b[39m*\u001b[39;49m x_mask\n\u001b[1;32m    295\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mE \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mE \u001b[39m*\u001b[39m e_mask1 \u001b[39m*\u001b[39m e_mask2\n\u001b[1;32m    296\u001b[0m     \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mallclose(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mE, torch\u001b[39m.\u001b[39mtranspose(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mE, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (15) must match the size of tensor b (12) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "model.forward(noisy_data, extra_data, node_mask).X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
